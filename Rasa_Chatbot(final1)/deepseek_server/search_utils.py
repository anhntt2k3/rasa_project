import chromadb
from sentence_transformers import SentenceTransformer, CrossEncoder
from sklearn.metrics.pairwise import cosine_similarity
import time

# ğŸ“‚ Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n
CHROMA_DB_PATH = "./chroma_db"

# ğŸ› ï¸ Load mÃ´ hÃ¬nh embedding
print("ğŸ”„ Äang táº£i mÃ´ hÃ¬nh embedding...")
bi_encoder = SentenceTransformer("intfloat/e5-base-v2")
cross_encoder = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-12-v2")

# ğŸ› ï¸ Káº¿t ná»‘i ChromaDB
print("ğŸ”„ Äang káº¿t ná»‘i ChromaDB...")
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
collection = chroma_client.get_or_create_collection(name="qa_collection")

# HÃ m remove_semantic_duplicates
def remove_semantic_duplicates(results, threshold=0.9):
    """Loáº¡i bá» cÃ¡c cÃ¢u há»i trÃ¹ng láº·p vá» Ã½ nghÄ©a báº±ng cosine similarity"""
    if not results:
        return []

    questions = [q for q, _ in results]
    embeddings = bi_encoder.encode(questions)  # MÃ£ hÃ³a táº¥t cáº£ cÃ¢u há»i thÃ nh vector
    similarity_matrix = cosine_similarity(embeddings)

    unique_results = []
    seen_indices = set()

    for i in range(len(results)):
        if i in seen_indices:
            continue
        unique_results.append(results[i])
        
        # ÄÃ¡nh dáº¥u nhá»¯ng cÃ¢u cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao Ä‘á»ƒ bá» qua
        for j in range(i + 1, len(results)):
            if similarity_matrix[i, j] > threshold:
                seen_indices.add(j)

    return unique_results

# ğŸ” TÃ¬m kiáº¿m trong ChromaDB
def search_chromadb(query, top_k=10):
    """TÃ¬m kiáº¿m trong ChromaDB sá»­ dá»¥ng Bi-Encoder"""
    start_embed_time = time.time()  # â± Báº¯t Ä‘áº§u Ä‘o thá»i gian embedding

    query_vector = bi_encoder.encode([query]).tolist()
    embed_time = time.time() - start_embed_time  # â± TÃ­nh thá»i gian embedding
    print(f"âš¡ Embedding time: {embed_time:.4f} seconds")  # Debug log

    start_search_time = time.time()  # â± Báº¯t Ä‘áº§u Ä‘o thá»i gian search
    results = collection.query(query_embeddings=query_vector, n_results=top_k)
    search_time = time.time() - start_search_time  # â± TÃ­nh thá»i gian search
    print(f"ğŸ” ChromaDB search time: {search_time:.4f} seconds")  # Debug log

    if not results["ids"]:
        return []
    
    return [(results["metadatas"][0][i]["question"], results["metadatas"][0][i]["answer"]) for i in range(len(results["ids"][0]))]

# ğŸ”¥ TÃ¬m kiáº¿m vÃ  rerank vá»›i Cross-Encoder
def rerank_results(query, search_results, top_m=3):
    """Rerank danh sÃ¡ch káº¿t quáº£ tÃ¬m kiáº¿m vá»›i Cross-Encoder"""

    start_time = time.time()  # â± Báº¯t Ä‘áº§u Ä‘o thá»i gian

    if not search_results:
        return ["âŒ KhÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i phÃ¹ há»£p."]
    
    search_results = remove_semantic_duplicates(search_results, threshold=0.9)

    # Táº¡o danh sÃ¡ch cáº·p (query, question + answer)
    cross_encoder_inputs = [(query, f"{qa[0]} {qa[1]}") for qa in search_results]

    # TÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
    cross_scores = cross_encoder.predict(cross_encoder_inputs)

    # Sáº¯p xáº¿p theo Ä‘iá»ƒm sá»‘ giáº£m dáº§n
    sorted_results = sorted(zip(search_results, cross_scores), key=lambda x: x[1], reverse=True)

    # Chá»‰ láº¥y top-M káº¿t quáº£ mÃ  khÃ´ng cáº§n kiá»ƒm tra ngÆ°á»¡ng
    final_answers = [q_a for (q_a, _) in sorted_results[:top_m]]

    elapsed_time = time.time() - start_time  # â± TÃ­nh thá»i gian thá»±c thi
    print(f"âš¡ Rerank time: {elapsed_time:.4f} seconds")  # Debug log

    return final_answers

print("âœ… Há»‡ thá»‘ng tÃ¬m kiáº¿m (ChromaDB) Ä‘Ã£ sáºµn sÃ ng!")
